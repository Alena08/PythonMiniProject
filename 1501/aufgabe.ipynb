{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad7fd85e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1078f2dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Machine Learning benötigt   saubere Daten!\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc553b91",
   "metadata": {},
   "source": [
    "Normalising"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b2c3adac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "machine learning benötigt   saubere daten\n",
      "Normalisierter Text: 'machine learning benötigt saubere daten'\n"
     ]
    }
   ],
   "source": [
    "# Kleinschreibung\n",
    "text = text.lower()\n",
    "# Sonderzeichen ersetzen\n",
    "text_clean = re.sub(r'[^a-zäöüß ]', '', text)\n",
    "print(text_clean)\n",
    "text_normalized = re.sub(r'\\s+', ' ', text_clean).strip()\n",
    "print(f\"Normalisierter Text: '{text_normalized}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8a66ff0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Normalisierter Text: 'machine learning benötigt saubere daten'\n",
      "Numerische Codes: \n",
      "[23, 11, 13, 18, 19, 24, 15, 10, 22, 15, 11, 28, 24, 19, 24, 17, 10, 12, 15, 24, 38, 30, 19, 17, 30, 10, 29, 11, 31, 12, 15, 28, 15, 10, 14, 11, 30, 15, 24]\n",
      "Vergleich: 39 39\n",
      "Statistische Häufigkeit[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 4, 4, 2, 1, 1, 6, 0, 2, 1, 3, 0, 0, 1, 1, 5, 0, 0, 0, 2, 1, 3, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0]\n",
      "39\n"
     ]
    }
   ],
   "source": [
    "class CharArray:\n",
    "\n",
    "    CHAR_MAP = {'0': 0, '1': 1, '2': 2, '3': 3, '4': 4, '5': 5,\n",
    "        '6': 6, '7': 7, '8': 8, '9': 9, ' ': 10,\n",
    "        'a': 11, 'b': 12, 'c': 13, 'd': 14, 'e': 15,\n",
    "        'f': 16, 'g': 17, 'h': 18, 'i': 19, 'j': 20,\n",
    "        'k': 21, 'l': 22, 'm': 23, 'n': 24, 'o': 25,\n",
    "        'p': 26, 'q': 27, 'r': 28, 's': 29, 't': 30,\n",
    "        'u': 31, 'v': 32, 'w': 33, 'x': 34, 'y': 35,\n",
    "        'z': 36, 'ä': 37, 'ö': 38, 'ü': 39, 'ß': 40\n",
    "    }\n",
    "    EXCLUDE = re.compile('[^0-9 a-zäüöß]+')\n",
    "    BLANKS = re.compile(' +')\n",
    "\n",
    "    def normalize(self, text):\n",
    "        # Kleinschreibung\n",
    "        text = text.lower()\n",
    "        # Sonderzeichen ersetzen\n",
    "        #print('1.',text)\n",
    "        text = self.EXCLUDE.sub(' ', text)\n",
    "        #print('2.1', text)\n",
    "        text = text.strip(' ')\n",
    "        #print('2.',text)\n",
    "        # Mehrere Leerzeichen durch eins ersetzen\n",
    "        text = self.BLANKS.sub(' ', text)\n",
    "        #print('3.',text)\n",
    "        return text\n",
    "\n",
    "    def process(self, text):\n",
    "        text = self.normalize(text)\n",
    "        result = [self.CHAR_MAP[char] for char in text]\n",
    "        return result\n",
    "\n",
    "    def stats(self, text):\n",
    "        chars = self.process(text)\n",
    "        result = [0 for _ in range(0, 41)]\n",
    "        #print('4.', result)\n",
    "        for code in chars:\n",
    "            result[code] += 1\n",
    "#            print(result)\n",
    "        return result\n",
    "\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    ca = CharArray()\n",
    "    text = '''Machine Learning benötigt saubere Daten!'''\n",
    "    x = ca.normalize(text)\n",
    "    print(f\"Normalisierter Text: '{x}'\")\n",
    "    y = ca.process(text)\n",
    "    print(f\"Numerische Codes: \\n{y}\")\n",
    "    print('Vergleich:', len(x), len(y))\n",
    "    z  = ca.stats(text)\n",
    "    print(f\"Statistische Häufigkeit: {z}\")\n",
    "    print(sum(z))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e708ad1f",
   "metadata": {},
   "source": [
    "# Aufgabe 2: Bag of Words mit CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a92fb8e3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine Learning mit Python' 'Python wird für Data Science genutzt'\n",
      " 'Learning Algorithmen benötigen Daten']\n",
      "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
      "\twith 14 stored elements and shape (3, 12)>\n",
      "  Coords\tValues\n",
      "  (0, 7)\t1\n",
      "  (0, 6)\t1\n",
      "  (0, 8)\t1\n",
      "  (0, 9)\t1\n",
      "  (1, 9)\t1\n",
      "  (1, 11)\t1\n",
      "  (1, 4)\t1\n",
      "  (1, 2)\t1\n",
      "  (1, 10)\t1\n",
      "  (1, 5)\t1\n",
      "  (2, 6)\t1\n",
      "  (2, 0)\t1\n",
      "  (2, 1)\t1\n",
      "  (2, 3)\t1\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<Compressed Sparse Row sparse matrix of dtype 'int64'\n",
       "\twith 14 stored elements and shape (3, 12)>"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import numpy as np\n",
    "strings = [\n",
    "\"Machine Learning mit Python\",\n",
    "\"Python wird für Data Science genutzt\",\n",
    "\"Learning Algorithmen benötigen Daten\"\n",
    "]\n",
    "\n",
    "string_data = np.array(strings)\n",
    "print(string_data)\n",
    "vectorizer = CountVectorizer()\n",
    "bag_of_words = vectorizer.fit_transform(string_data)\n",
    "print(bag_of_words)\n",
    "bag_of_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "95423ec2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0],\n",
       "       [0, 0, 1, 0, 1, 1, 0, 0, 0, 1, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Matrix in array umwandeln (Bag of Words Format)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7521e1f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['algorithmen', 'benötigen', 'data', 'daten', 'für', 'genutzt',\n",
       "       'learning', 'machine', 'mit', 'python', 'science', 'wird'],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste der unterschiedlichen Wörter\n",
    "vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86f83ff8",
   "metadata": {},
   "source": [
    "Entfernen Sie Stoppwörter: [\"mit\", \"für\", \"wird\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "efd8741c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 1, 1, 1, 0],\n",
       "       [0, 0, 1, 0, 1, 0, 0, 1, 1],\n",
       "       [1, 1, 0, 1, 0, 1, 0, 0, 0]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Stopwords für deutschen Text\n",
    "stop = [\"mit\", \"für\", \"wird\"]\n",
    "vectorizer2 = CountVectorizer(stop_words = stop)\n",
    "bag_of_words = vectorizer2.fit_transform(string_data)\n",
    "bag_of_words.toarray()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b67920d",
   "metadata": {},
   "source": [
    "Geben Sie die Feature-Namen "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "c89787d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['algorithmen', 'benötigen', 'data', 'daten', 'genutzt', 'learning',\n",
       "       'machine', 'python', 'science'], dtype=object)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Liste der unterschiedlichen Wörter\n",
    "vectorizer2.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b98b097c",
   "metadata": {},
   "source": [
    "# Aufgabe 3: Bigramme erzeugen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6e109769",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['algorithmen benötigen', 'benötigen daten', 'data science',\n",
       "       'learning algorithmen', 'learning python', 'machine learning',\n",
       "       'python data', 'science genutzt'], dtype=object)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer3 = CountVectorizer(stop_words = stop, ngram_range = (2, 2))\n",
    "bigrams = vectorizer3.fit_transform(string_data)\n",
    "vectorizer3.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5719b96e",
   "metadata": {},
   "source": [
    "# Aufgabe 4: Große Texte mit HashingVectorizer komprimieren"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "af04cc49",
   "metadata": {},
   "outputs": [],
   "source": [
    "texts = [\n",
    "\"\"\"Ein tagged VLAN (Virtual Local Area Network) nach dem Standard IEEE 802.1Q ist eine Methode,\n",
    " um mehrere getrennte Netzwerke über ein und dasselbe physische Kabel zu schicken.\n",
    "Stellen Sie sich ein VLAN wie eine Trennwand in einem Büro vor. Ein tagged VLAN ist dann wie ein Postsystem, \n",
    "bei dem jeder Brief einen Aufkleber (Tag) erhält, damit der Empfänger weiß, in welche Abteilung (VLAN) der Brief gehört.\n",
    "1. Das Problem ohne Tagging\n",
    "Normalerweise gehört ein Port an einem Switch zu genau einem Netzwerk. \n",
    "Wenn Sie 3 verschiedene Netzwerke (z. B. Buchhaltung, Gäste-WLAN und Produktion) von einem Switch zum nächsten übertragen wollten, \n",
    "müssten Sie 3 separate Kabel ziehen.\n",
    "\n",
    "2. Die Lösung: Der \"Tag\"\n",
    "Beim Tagging wird in den Header jedes Datenpakets (Ethernet-Frame) eine kleine Information eingefügt: die VLAN-ID (eine Zahl zwischen 1 und 4094).\n",
    "Der Prozess: Wenn ein Paket einen Switch verlässt,\n",
    " um über eine Verbindungsleitung (Trunk) zu einem anderen Switch zu gehen, klebt der Switch das \"Tag\" auf das Paket.\n",
    "\n",
    "Der Empfang: Der Ziel-Switch liest das Tag, sieht z. B. \"VLAN 20\", entfernt das Tag wieder und leitet das Paket nur an die Anschlüsse weiter,\n",
    " die ebenfalls zum VLAN 20 gehören.\n",
    "\"\"\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "7c4bedd2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import HashingVectorizer\n",
    "import numpy as np\n",
    "\n",
    "text_data = np.array(texts)\n",
    "hv = HashingVectorizer(n_features = 10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "97d99ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[-0.17149859, -0.45732956, -0.0571662 ,  0.22866478, -0.45732956,\n",
       "         0.17149859, -0.17149859,  0.11433239, -0.40016337, -0.51449576]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features = hv.transform(text_data)\n",
    "#print(features)\n",
    "features.toarray()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
